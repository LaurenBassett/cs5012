{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5012_HW2_sortFirst.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgaqXBYJDx0D"
      },
      "source": [
        "# 5012 HW #2. Improve code Efficiency: Sort First!\n",
        "\n",
        "##Scenario. \n",
        "\n",
        "In a two class, classification problem, it is common to use a classifier that outputs confidences (rather than simply class labels). A good example of this is a Support Vector Machine. A pro for using such a classifier is that you gain more information -- specifically the confidence in the classification result. A con is that in order to make a final classification decision, a threshold value must be determined. For example, if a threshold of .75 is chosen, the class label 1 would be assigned for confidences greater than .75 and for confidences less than .75 a class label of 0 would be assigned. However, this begs the question: how is the threshold chosen?\n",
        "\n",
        "Many data scientist will choose a threshold based on the experimental results and/or operational constraints. In this code example, we assume that we have confidences and true labels for a large data set. To determine a good threshold we will compute the true positive and false positive rates at all relevant thresholds. The relevant thresholds are consider those that would change the TPRs and FPRs. \n",
        "\n",
        "In the code below, a function is defined to compute the TPR and FPR at all relevant thresholds. However, the code is not very efficient and can be improved. (Note there are tips and hints found in the comments.) \n",
        "\n",
        "Your task is the following:\n",
        "\n",
        "##Question 1:\n",
        "Assess the time complexity of the method computeAllTPRs(...). Provide a line-by-line assessment in comments identifying the proportional number of steps (bounding notation is sufficient) per line: eg, O(1), O(log n), O(n), etc. Also, derive a time step function T(n) for the entire method (where n is the size of input true_label).\n",
        "\n",
        "##Question 2:\n",
        "Implement a new function computeAllTPRs_improved(...) which performs the same task as computeAllTPRs but has a significantly reduced time complexity. Also provide a line-by-line assessment in comments identifying the proportional number of steps per line, and derive a time step function T(n) for the entire method (where n is the size of input true_label).\n",
        "\n",
        "##Question 3:\n",
        "Compare the theoretical time complexities of both methods and predict which is more efficient. Next, test your prediction by timing both methods on sample inputs of varying sizes. Create a plot of inputSize vs runtime (as done in similar class examples.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQs8b3ccEskN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "from numpy import argmax\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4t6Gd-XNWdr"
      },
      "source": [
        "Answer Question #1 in the comments of the code chunk below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFu90tkjEORa"
      },
      "source": [
        "    def computeAllTPRs(true_label, confs):\n",
        "        '''\n",
        "\n",
        "        inputs:\n",
        "         - true_label: list of labels, assumed to be 0 or 1 (a two class problem)\n",
        "         - confs: list of confidences\n",
        "\n",
        "        This method computes the True Positive Rate (TPRs) and FPRs for all relevant\n",
        "        thresholds given true_label and confs. Relevant thresholds are considered\n",
        "        all different values found in confs.\n",
        "        '''\n",
        "\n",
        "        # Define / initialize  variables\n",
        "        sentinelValue = -1 # used to replace max value found thus far\n",
        "        totalPositives = sum(true_label)\n",
        "        totalNegatives = len(true_label) - totalPositives \n",
        "        #print(true_label)\n",
        "        truePositives = 0\n",
        "        falsePositives = 0\n",
        "        # Hint: Consider Memory Management\n",
        "        truePositiveRate = []\n",
        "        falsePositiveRate = []\n",
        "\n",
        "        #Hint: Although not explicitly clear, the loop structure below is an \n",
        "            #embeded loop ie, O(n^2) ... do you see why??\n",
        "        #Hint: If you sort the confidences first you can improve the iteration scheme.\n",
        "        \n",
        "        # Iterate over all relevant thresholds. Compute TPR and FPR for each and \n",
        "        # append to truePositiveRate , falsePositiveRate lists. \n",
        "\n",
        "        for i in range(len(confs)):\n",
        "          maxVal = max(confs)  # Hint: the max method does NOT run in O(1) \n",
        "          argMax = argmax(confs)\n",
        "          confs[argMax] = sentinelValue\n",
        "          #print(argMax)\n",
        "          if true_label[argMax]==1:\n",
        "            truePositives += 1\n",
        "          else:\n",
        "            falsePositives += 1\n",
        "\n",
        "          truePositiveRate.append(truePositives/totalPositives)\n",
        "          falsePositiveRate.append(falsePositives/totalNegatives)\n",
        "          #print(truePositiveRate)\n",
        "\n",
        "        # Plot FPR vs TPR for all possible thresholds \n",
        "        plt.plot(falsePositiveRate,truePositiveRate, label ='class' + str(i) + ' to all')\n",
        "        plt.legend()\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.show()\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeQPCILfGPSV"
      },
      "source": [
        "def testComputeAllTPRs(numSamples):\n",
        "\n",
        "  #Generate 5 random numbers between 10 and 30\n",
        "  confList = []\n",
        "  labels = []\n",
        "  maxVal = 10000\n",
        "  #numSamples = 10000\n",
        "  for i in range(0,numSamples):\n",
        "    n = random.randint(1,maxVal)\n",
        "    confList.append(n/maxVal)\n",
        "    n = random.randint(1,maxVal)\n",
        "    if n/maxVal > .5: \n",
        "      lab = 1 \n",
        "    else: \n",
        "      lab = 0\n",
        "    labels.append(lab)\n",
        "  #print(labels)\n",
        "  computeAllTPRs(labels, deepcopy(confList))  # Why a deepcopy here?\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0aNsuFFMzLt"
      },
      "source": [
        "Below, provide you implementation for Question #2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4SoYMYBMyzA"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP72j3GqM6AH"
      },
      "source": [
        "Question #3. Below, provide your code which records and plots the runtime for the original and improved methods. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfIyurNcNJUL"
      },
      "source": [
        "testComputeAllTPRs()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}